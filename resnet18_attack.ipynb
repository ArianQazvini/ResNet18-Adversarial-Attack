{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, Subset, TensorDataset, DataLoader\n",
    "import torchattacks \n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms.functional as TF\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import glob\n",
    "from torchvision import transforms\n",
    "import random\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from autoattack import AutoAttack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RIVAL10(Dataset):    \n",
    "    def __init__(self, train=True, return_masks=False, data_root=\"..\"):\n",
    "\n",
    "        self.train = train\n",
    "        self.return_masks = return_masks\n",
    "        self.instance_types = ['ordinary']\n",
    "\n",
    "        root_data = data_root + \"/{}/\"\n",
    "        self.data_root = root_data.format('train' if self.train else 'test')\n",
    "\n",
    "        root_mask = data_root + \"/{}/entire_object_masks/\"\n",
    "        self.mask_root = root_mask.format('train' if self.train else 'test')\n",
    "\n",
    "        with open(data_root + \"/meta/label_mappings.json\", 'r') as f:\n",
    "            self.label_mappings = json.load(f)\n",
    "        with open(data_root + \"/meta/wnid_to_class.json\", 'r') as f:\n",
    "            self.wnid_to_class = json.load(f)\n",
    "\n",
    "        self.collect_instances()\n",
    "        self.collect_images()\n",
    "\n",
    "    def get_rival10_og_class(self, img_url):\n",
    "        wnid = img_url.replace('\\\\', '/').split('/')[-1].split('_')[0]\n",
    "        inet_class_name = self.wnid_to_class[wnid]\n",
    "        classname, class_label = self.label_mappings[inet_class_name]\n",
    "        return classname, class_label\n",
    "\n",
    "    def collect_instances(self):\n",
    "        self.instances_by_type = dict()\n",
    "        self.all_instances = []\n",
    "        for subdir in self.instance_types:\n",
    "            instances = []\n",
    "            dir_path = self.data_root + subdir\n",
    "            for f in tqdm(glob.glob(dir_path + '/*')):\n",
    "                if '.JPEG' in f and 'merged_mask' not in f:\n",
    "                    img_url = f\n",
    "                    label_path = f[:-5] + '_attr_labels.npy'\n",
    "                    merged_mask_path = f[:-5] + '_merged_mask.JPEG'\n",
    "                    mask_dict_path = f[:-5] + '_attr_dict.pkl'\n",
    "                    instances.append((img_url, label_path, merged_mask_path, mask_dict_path))\n",
    "            self.instances_by_type[subdir] = instances.copy()\n",
    "            self.all_instances.extend(self.instances_by_type[subdir])\n",
    "\n",
    "    def transform(self, imgs):\n",
    "        transformed_imgs = []\n",
    "        resize = transforms.Resize((224, 224))\n",
    "        i, j, h, w = transforms.RandomResizedCrop.get_params(imgs[0], scale=(0.8, 1.0), ratio=(0.75, 1.25))\n",
    "        coin_flip = (random.random() < 0.5)\n",
    "        for ind, img in enumerate(imgs):\n",
    "            if self.train:\n",
    "                img = TF.crop(img, i, j, h, w)\n",
    "\n",
    "                if coin_flip:\n",
    "                    img = TF.hflip(img)\n",
    "\n",
    "            img = TF.to_tensor(resize(img))\n",
    "\n",
    "            if img.shape[0] == 1:\n",
    "                img = torch.cat([img, img, img], axis=0)\n",
    "\n",
    "            transformed_imgs.append(img)\n",
    "\n",
    "        return transformed_imgs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_instances)\n",
    "\n",
    "    def collect_images(self):\n",
    "\n",
    "        self.all_images = []\n",
    "\n",
    "        for img_url, label_path, merged_mask_path, mask_dict_path in tqdm(self.all_instances):\n",
    "\n",
    "            class_name, class_label = self.get_rival10_og_class(img_url)\n",
    "\n",
    "            img = Image.open(img_url)\n",
    "            if img.mode == 'L':\n",
    "                img = img.convert(\"RGB\")\n",
    "\n",
    "            imgs = [img]\n",
    "\n",
    "            if self.return_masks:\n",
    "                merged_mask_img = Image.open(merged_mask_path)\n",
    "                imgs = [img, merged_mask_img]\n",
    "\n",
    "            imgs = self.transform(imgs)\n",
    "\n",
    "            if self.return_masks:\n",
    "                self.all_images.append([imgs[0], imgs[1], class_label])\n",
    "            else:\n",
    "                self.all_images.append([imgs[0], class_label, img_url])\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "\n",
    "        return self.all_images[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(num_samples=300, batch_size=128, rival_mask=False):\n",
    "    \n",
    "    trainset = RIVAL10(train=True, return_masks=rival_mask)\n",
    "       \n",
    "    subset_indices = list(range(num_samples))\n",
    "    rival_subset = Subset(trainset, subset_indices)\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(rival_subset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    num_classes = 10\n",
    "\n",
    "    return trainloader, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_saved_images(org_path, tl_path):\n",
    "    true_labels = []\n",
    "    original_imgs = []\n",
    "    with open(tl_path, 'rb') as file:\n",
    "        true_labels = pickle.load(file)\n",
    "    \n",
    "    with open(org_path, 'rb') as file:\n",
    "        original_imgs = pickle.load(file)\n",
    "    \n",
    "    return true_labels, original_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoattack_adversarial_images(model, original_imgs, true_labels, batch_size=128):\n",
    "    model.train()  \n",
    "\n",
    "    adversarial_images = []\n",
    "    \n",
    "\n",
    "    auto_attack = AutoAttack(model, norm='Linf', eps=2/255, version='standard', device=device)\n",
    "    \n",
    "    for batch_idx, images in enumerate(original_imgs):\n",
    "        labels = true_labels[batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "    \n",
    "        adv_imgs = auto_attack.run_standard_evaluation(images, labels, bs=batch_size)\n",
    "        adversarial_images.append(adv_imgs.cpu())  \n",
    "\n",
    "    return adversarial_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pgd_adversarial_images(model, original_imgs, true_labels, batch_size=128, epsilon=2/255, alpha=2/255, steps=10):\n",
    "    model.train()\n",
    "    \n",
    "    adversarial_images = []\n",
    "    \n",
    "\n",
    "    attack = torchattacks.PGD(model, eps=epsilon, alpha=alpha, steps=steps)\n",
    "\n",
    "    for batch_idx, images in enumerate(original_imgs):\n",
    "        \n",
    "        labels = true_labels[batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "\n",
    "        adv_imgs = attack(images, labels)\n",
    "        adversarial_images.append(adv_imgs.cpu()) \n",
    "    \n",
    "    return adversarial_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cw_adversarial_images(model, original_imgs, true_labels, batch_size=128, c=1e-4, kappa=0, lr=0.01, steps=1000):\n",
    "    model.train()\n",
    "    \n",
    "    adversarial_images = []\n",
    "    \n",
    "\n",
    "    attack = torchattacks.CW(model, c=c, kappa=kappa, steps=steps, lr=lr)\n",
    "    \n",
    "    for batch_idx, images in enumerate(original_imgs):\n",
    "        labels = true_labels[batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "\n",
    "        adv_imgs = attack(images, labels)\n",
    "        adversarial_images.append(adv_imgs.cpu())  \n",
    "    \n",
    "    return adversarial_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fgsm_adversarial_images(model, original_imgs, true_labels, epsilon=0.007, batch_size=128):\n",
    "    model.train()  \n",
    "\n",
    "    adversarial_images = []\n",
    "\n",
    "\n",
    "    attack = torchattacks.FGSM(model, eps=epsilon)\n",
    "\n",
    "    for batch_idx, images in enumerate(original_imgs):\n",
    "        labels = true_labels[batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        adv_imgs = attack(images, labels)\n",
    "        adversarial_images.append(adv_imgs.cpu())  # Store on CPU to save memory\n",
    "\n",
    "    return adversarial_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_asr(model, adversarial_images, true_labels, batch_size=128):\n",
    "    incorrect = 0\n",
    "    total = len(true_labels)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, images in enumerate(adversarial_images):\n",
    "            labels = true_labels[batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.eval()\n",
    "     \n",
    "            with torch.no_grad():\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            # print('Predicted:',predicted)\n",
    "            # print('True Labels:',labels)\n",
    "            # print('-------------------')\n",
    "            incorrect += (predicted != labels).sum().item()\n",
    "        \n",
    "        asr = incorrect / total\n",
    "    return asr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acc(model,original_images, true_labels, batch_size=128):\n",
    "    correct = 0\n",
    "    total = len(true_labels)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, images in enumerate(original_images):\n",
    "            labels = true_labels[batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.eval()\n",
    "     \n",
    "            with torch.no_grad():\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            # print('Predicted:',predicted)\n",
    "            # print('True Labels:',labels)\n",
    "            # print('-------------------')\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        acc = correct / total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_path = '..'\n",
    "org_path = '..'\n",
    "true_labels, original_imgs = load_saved_images(org_path, tl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Clean: 97.6\n"
     ]
    }
   ],
   "source": [
    "pretrained_path = '..'\n",
    "model_res18 = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "num_ftrs = model_res18.fc.in_features\n",
    "model_res18.fc = nn.Linear(num_ftrs, 10)\n",
    "model_res18.load_state_dict(torch.load(pretrained_path))\n",
    "model_res18 = model_res18.to(device)\n",
    "\n",
    "print(f'Accuracy on Clean: {calculate_acc(model_res18, original_imgs,true_labels) * 100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PGD attack...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGD Attack Success Rate = 98.00%\n",
      "--------------------\n",
      "Running FGSM attack...\n",
      "FGSM Attack Success Rate = 75.80%\n",
      "--------------------\n",
      "Running AutoAttack attack...\n",
      "setting parameters for standard version\n",
      "using standard version including apgd-ce, apgd-t, fab-t, square.\n",
      "initial accuracy: 95.31%\n",
      "apgd-ce - 1/1 - 119 out of 122 successfully perturbed\n",
      "robust accuracy after APGD-CE: 2.34% (total time 35.7 s)\n",
      "apgd-t - 1/1 - 3 out of 3 successfully perturbed\n",
      "robust accuracy after APGD-T: 0.00% (total time 37.6 s)\n",
      "max Linf perturbation: 0.00784, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
      "robust accuracy: 0.00%\n",
      "using standard version including apgd-ce, apgd-t, fab-t, square.\n",
      "initial accuracy: 97.66%\n",
      "apgd-ce - 1/1 - 112 out of 125 successfully perturbed\n",
      "robust accuracy after APGD-CE: 10.16% (total time 36.6 s)\n",
      "apgd-t - 1/1 - 12 out of 13 successfully perturbed\n",
      "robust accuracy after APGD-T: 0.78% (total time 42.9 s)\n",
      "fab-t - 1/1 - 1 out of 1 successfully perturbed\n",
      "robust accuracy after FAB-T: 0.00% (total time 46.3 s)\n",
      "max Linf perturbation: 0.00784, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
      "robust accuracy: 0.00%\n",
      "using standard version including apgd-ce, apgd-t, fab-t, square.\n",
      "initial accuracy: 97.66%\n",
      "apgd-ce - 1/1 - 116 out of 125 successfully perturbed\n",
      "robust accuracy after APGD-CE: 7.03% (total time 36.7 s)\n",
      "apgd-t - 1/1 - 8 out of 9 successfully perturbed\n",
      "robust accuracy after APGD-T: 0.78% (total time 41.7 s)\n",
      "fab-t - 1/1 - 1 out of 1 successfully perturbed\n",
      "robust accuracy after FAB-T: 0.00% (total time 41.7 s)\n",
      "max Linf perturbation: 0.00784, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
      "robust accuracy: 0.00%\n",
      "using standard version including apgd-ce, apgd-t, fab-t, square.\n",
      "initial accuracy: 98.28%\n",
      "apgd-ce - 1/1 - 105 out of 114 successfully perturbed\n",
      "robust accuracy after APGD-CE: 7.76% (total time 33.7 s)\n",
      "apgd-t - 1/1 - 8 out of 9 successfully perturbed\n",
      "robust accuracy after APGD-T: 0.86% (total time 38.7 s)\n",
      "fab-t - 1/1 - 1 out of 1 successfully perturbed\n",
      "robust accuracy after FAB-T: 0.00% (total time 38.7 s)\n",
      "max Linf perturbation: 0.00784, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
      "robust accuracy: 0.00%\n",
      "AutoAttack Attack Success Rate = 92.20%\n",
      "--------------------\n",
      "Running CW attack...\n",
      "CW Attack Success Rate = 74.00%\n",
      "--------------------\n",
      "PGD: Attack Success Rate = 98.00%\n",
      "FGSM: Attack Success Rate = 75.80%\n",
      "AutoAttack: Attack Success Rate = 92.20%\n",
      "CW: Attack Success Rate = 74.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "attacks = [\n",
    "        ('PGD', create_pgd_adversarial_images),\n",
    "        ('FGSM', create_fgsm_adversarial_images),\n",
    "        ('AutoAttack', create_autoattack_adversarial_images),\n",
    "        ('CW', create_cw_adversarial_images)\n",
    "    ]\n",
    "\n",
    "attack_success_rates = []\n",
    "\n",
    "\n",
    "for attack_name, attack_func in attacks:\n",
    "        print(f\"Running {attack_name} attack...\")\n",
    "        adversarial_images = attack_func(model_res18, original_imgs, true_labels)\n",
    "        attack_success_rate = calculate_asr(model_res18, adversarial_images,true_labels)\n",
    "        attack_success_rates.append((attack_name, attack_success_rate))\n",
    "        print(f'{attack_name} Attack Success Rate = {attack_success_rate * 100:.2f}%')\n",
    "        print('--------------------')\n",
    "\n",
    "\n",
    "for attack_name, asr in attack_success_rates:\n",
    "        print(f'{attack_name}: Attack Success Rate = {asr * 100:.2f}%')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
